#!/usr/bin/env python3
"""
æ•°æ®é›†éªŒè¯è„šæœ¬
æ£€æŸ¥è®­ç»ƒæ•°æ®é›†ä¸­æ˜¯å¦èƒ½å¤Ÿæ­£ç¡®æå–åŸå§‹ç”¨æˆ·é—®é¢˜
"""

import json
import os
import sys
from typing import List, Tuple

def extract_original_question(prompt_text: str) -> str:
    """ä»å®Œæ•´çš„promptä¸­æå–åŸå§‹ç”¨æˆ·é—®é¢˜"""
    # æŸ¥æ‰¾ "User query:" æ ‡è®°åçš„å†…å®¹
    if "User query:" not in prompt_text:
        raise ValueError(f"âŒ åœ¨promptä¸­æœªæ‰¾åˆ°'User query:'æ ‡è®°")
    
    start_idx = prompt_text.find("User query:") + len("User query:")
    
    # æ‰¾åˆ°"Graph evidence:"çš„ä½ç½®
    end_idx = prompt_text.find("Graph evidence:", start_idx)
    if end_idx == -1:
        raise ValueError(f"âŒ åœ¨promptä¸­æœªæ‰¾åˆ°'Graph evidence:'æ ‡è®°")
    
    question = prompt_text[start_idx:end_idx].strip()
    
    if not question:
        raise ValueError(f"âŒ æå–çš„é—®é¢˜ä¸ºç©º")
    
    return question

def validate_dataset(dataset_path: str) -> Tuple[int, int, List[dict]]:
    """
    éªŒè¯æ•°æ®é›†
    è¿”å›: (æˆåŠŸæ•°é‡, æ€»æ•°é‡, é”™è¯¯åˆ—è¡¨)
    """
    success_count = 0
    total_count = 0
    errors = []
    
    print(f"ğŸ” å¼€å§‹éªŒè¯æ•°æ®é›†: {dataset_path}")
    
    if not os.path.exists(dataset_path):
        print(f"âŒ æ•°æ®é›†æ–‡ä»¶ä¸å­˜åœ¨: {dataset_path}")
        return 0, 0, [{"error": "æ–‡ä»¶ä¸å­˜åœ¨", "path": dataset_path}]
    
    with open(dataset_path, 'r', encoding='utf-8') as f:
        for line_num, line in enumerate(f, 1):
            total_count += 1
            
            try:
                # è§£æJSONè¡Œ
                data = json.loads(line.strip())
                
                # æ£€æŸ¥å¿…è¦å­—æ®µ
                if 'prompt' not in data:
                    errors.append({
                        "line": line_num,
                        "error": "ç¼ºå°‘'prompt'å­—æ®µ",
                        "data_keys": list(data.keys())
                    })
                    continue
                
                # å°è¯•æå–åŸå§‹é—®é¢˜
                original_question = extract_original_question(data['prompt'])
                
                # éªŒè¯æå–ç»“æœ
                if len(original_question) < 5:
                    errors.append({
                        "line": line_num,
                        "error": "æå–çš„é—®é¢˜è¿‡çŸ­",
                        "extracted": original_question
                    })
                    continue
                
                if len(original_question) > 500:
                    errors.append({
                        "line": line_num,
                        "error": "æå–çš„é—®é¢˜è¿‡é•¿",
                        "extracted_length": len(original_question),
                        "extracted_preview": original_question[:100] + "..."
                    })
                    continue
                
                success_count += 1
                
                # æ¯1000è¡Œæ‰“å°ä¸€æ¬¡è¿›åº¦
                if line_num % 1000 == 0:
                    print(f"âœ… å·²éªŒè¯ {line_num} è¡Œï¼ŒæˆåŠŸç‡: {success_count/line_num*100:.1f}%")
                
            except json.JSONDecodeError as e:
                errors.append({
                    "line": line_num,
                    "error": f"JSONè§£æé”™è¯¯: {e}",
                    "line_content": line[:100] + "..." if len(line) > 100 else line
                })
            except ValueError as e:
                errors.append({
                    "line": line_num,
                    "error": str(e),
                    "prompt_preview": data.get('prompt', '')[:200] + "..." if len(data.get('prompt', '')) > 200 else data.get('prompt', '')
                })
            except Exception as e:
                errors.append({
                    "line": line_num,
                    "error": f"æœªçŸ¥é”™è¯¯: {e}",
                    "data_preview": str(data)[:200] + "..." if len(str(data)) > 200 else str(data)
                })
    
    return success_count, total_count, errors

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ Trinity-RFT æ•°æ®é›†éªŒè¯å™¨")
    print("=" * 50)
    
    # å¾…éªŒè¯çš„æ•°æ®é›†è·¯å¾„
    dataset_paths = [
        "rl/datasets/rl_train/rl_train.jsonl",
        "rl/datasets/sft_train/sft_train.jsonl",
    ]
    
    total_success = 0
    total_count = 0
    all_errors = []
    
    for dataset_path in dataset_paths:
        print(f"\nğŸ“ éªŒè¯æ•°æ®é›†: {dataset_path}")
        print("-" * 40)
        
        success, count, errors = validate_dataset(dataset_path)
        total_success += success
        total_count += count
        
        print(f"ğŸ“Š éªŒè¯ç»“æœ:")
        print(f"   âœ… æˆåŠŸ: {success}/{count} ({success/count*100:.1f}%)")
        print(f"   âŒ å¤±è´¥: {len(errors)}")
        
        if errors:
            print(f"\nğŸ” é”™è¯¯è¯¦æƒ… (æ˜¾ç¤ºå‰5ä¸ª):")
            for i, error in enumerate(errors[:5]):
                print(f"   {i+1}. è¡Œ {error.get('line', 'N/A')}: {error.get('error', 'Unknown')}")
                if 'extracted' in error:
                    print(f"      æå–ç»“æœ: {error['extracted']}")
                if 'prompt_preview' in error:
                    print(f"      Prompté¢„è§ˆ: {error['prompt_preview']}")
                print()
        
        all_errors.extend(errors)
    
    print("\n" + "=" * 50)
    print(f"ğŸ“ˆ æ€»ä½“éªŒè¯ç»“æœ:")
    print(f"   âœ… æ€»æˆåŠŸ: {total_success}/{total_count} ({total_success/total_count*100:.1f}%)")
    print(f"   âŒ æ€»å¤±è´¥: {len(all_errors)}")
    
    if len(all_errors) == 0:
        print(f"ğŸ‰ æ‰€æœ‰æ•°æ®éƒ½èƒ½æ­£ç¡®æå–åŸå§‹é—®é¢˜ï¼å¯ä»¥å®‰å…¨è¿è¡Œè®­ç»ƒã€‚")
        return 0
    else:
        print(f"âš ï¸  å‘ç° {len(all_errors)} ä¸ªé—®é¢˜ï¼Œå»ºè®®ä¿®å¤åå†è¿è¡Œè®­ç»ƒã€‚")
        
        # ä¿å­˜é”™è¯¯æŠ¥å‘Š
        error_report_path = "rl/dataset_validation_errors.json"
        with open(error_report_path, 'w', encoding='utf-8') as f:
            json.dump(all_errors, f, ensure_ascii=False, indent=2)
        print(f"ğŸ“„ è¯¦ç»†é”™è¯¯æŠ¥å‘Šå·²ä¿å­˜åˆ°: {error_report_path}")
        
        return 1

if __name__ == "__main__":
    sys.exit(main())
